{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 79-character line limit\n",
    "######### ######### ######### ######### ######### ######### ######### #########\n",
    "%reset -f\n",
    "\n",
    "import numpy as np # The NumPy library\n",
    "#import math # The math module, np includes it\n",
    "from scipy.integrate import quad # Method for integration in scipy.integrate sub-package\n",
    "\n",
    "\n",
    "cells_num = 32\n",
    "\n",
    "# The sizes are for UQs for number of cells: 4, 8, 16, 32, 64, 128, 256.\n",
    "\n",
    "# The opitimized spaces for the Guassian distribution in a uniform quantizer(UQ).\n",
    "all_size_gaus = np.array([0.9957, 0.5860, 0.3352, 0.1881, 0.1041, 0.0569, 0.0308])\n",
    "\n",
    "# The opitimized spaces for the Laplacian distribution in a uniform quantizer(UQ).\n",
    "all_size_laplacian = np.array(\n",
    "                   [1.414, 1.0873, 0.8707, 0.7309, 0.6334, 0.5613, 0.5055])\n",
    "\n",
    "\n",
    "'''The opitimized spaces for a Mixed Gaussian distribution in \n",
    "a uniform quantizer(UQ). This distribution is not symmetric and the values are\n",
    "for for cells number 2, 4, 8, 16, 32, 64, 128, 256'''\n",
    "all_boudary1s = [-0.05, -2.02, -3.17, -3.93, -4.49, -5.08, -5.16, -5.50]\n",
    "all_deltas = [4, 1.81, 1, 0.54, 0.29, 0.16, 0.08, 0.05]\n",
    "\n",
    "'''To change the symmetric pdf, two parts of code must be changed include the \n",
    "cell_size and pdf'''\n",
    "\n",
    "cell_size = all_size_gaus[int(np.log2(cells_num))-2]\n",
    "# cell_size = all_size_laplacian[int(np.log2(cells_num))-2]\n",
    "\n",
    "# np.arange has rounding error issue.\n",
    "# boundaries_symm = np.arange(-(cells_num/2-1) * cell_size, # For symmetric distributions\n",
    "#                              (cells_num/2) * cell_size,\n",
    "#                             cell_size)\n",
    "\n",
    "# Boundaries for the symmetric distributions are computed.\n",
    "boundaries_symm = np.linspace(-(cells_num/2-1) * cell_size, # For symmetric distributions\n",
    "                               (cells_num/2-1) * cell_size,\n",
    "                              cells_num-1)\n",
    "\n",
    "# Boundaries for the asymmetric distributions are computed.\n",
    "boundary1 = all_boudary1s[int(np.log2(cells_num))-1]\n",
    "delta = all_deltas[int(np.log2(cells_num))-1]\n",
    "\n",
    "boundaries_asymm = []\n",
    "for i in range (0,cells_num-1):\n",
    "        boundary = boundary1 + (i) * delta\n",
    "        boundaries_asymm = np.append(boundaries_asymm, boundary)\n",
    "        \n",
    "'''To change the symmetric pdf to asymetric pdf, two parts of code \n",
    "must be changed include the boundaries and pdf'''        \n",
    "\n",
    "# boundaries = boundaries_symm # For symmetric distributions\n",
    "boundaries = boundaries_asymm # For asymetric distributions\n",
    "        \n",
    "\n",
    "n_inf = float(\"-inf\")\n",
    "p_inf = float(\"inf\")\n",
    "\n",
    "boundaries = np.insert(boundaries, 0, n_inf)\n",
    "boundaries = np.append(boundaries, p_inf)\n",
    "\n",
    "def pdf(x): # Defining the distribution\n",
    "#     gaus_std = 1\n",
    "#     gaus_mean = 0\n",
    "#     pdf = 1/(gaus_std*np.sqrt(2*np.pi)) * \\\n",
    "#                   np.exp(-0.5*((x-gaus_mean)/gaus_std)**2) # Gaussian pdf\n",
    "    \n",
    "#     div = 1\n",
    "#     pdf = 1/(2*div)*np.exp(-abs(x)/div) # Laplacian pdf\n",
    "\n",
    "    Mean1 = -2\n",
    "    Mean2 = 2\n",
    "    stdev1 = 1\n",
    "    stdev2 = 1\n",
    "    alpha = 0.7\n",
    "    pdf = (alpha)*(1/np.sqrt(2*np.pi*stdev1)*np.exp(-(x-Mean1)**2/(2*stdev1**2)))\\\n",
    "        + (1-alpha)*(1/np.sqrt(2*np.pi*stdev2)*np.exp(-(x-Mean2)**2/(2*stdev2**2)))\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "def xpdf(x):\n",
    "    xpdf = x * pdf(x)\n",
    "    return xpdf\n",
    "\n",
    "def x2pdf (x):\n",
    "    x2pdf = x * xpdf(x)\n",
    "    return x2pdf\n",
    "\n",
    "\n",
    "prbs = []\n",
    "xprbs = []\n",
    "x2prbs = []\n",
    "cell_reps = []\n",
    "for i in range (0, cells_num):\n",
    "    cell_prb, integ_err = quad(pdf, boundaries[i], boundaries[i+1])\n",
    "    prbs = np.append(prbs, cell_prb)\n",
    "    \n",
    "    cell_xprb, integ_err = quad(xpdf, boundaries[i], boundaries[i+1])\n",
    "    xprbs = np.append(xprbs, cell_xprb)\n",
    "    \n",
    "    cell_x2prb, integ_err = quad(x2pdf, boundaries[i], boundaries[i+1])\n",
    "    x2prbs = np.append(x2prbs, cell_x2prb)\n",
    "    \n",
    "    cell_rep = cell_xprb / cell_prb\n",
    "    cell_reps = np.append(cell_reps, cell_rep)\n",
    "    \n",
    "    \n",
    "# Function definitions\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def lrelu(x):\n",
    "    return np.where(x > 0, x, x * 0.1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and biases initialization\n",
    "\n",
    "l1_size = 32\n",
    "\n",
    "# W1 = np.random.randn(l1_size, cells_num)\n",
    "# B1 = np.zeros(l1_size,)\n",
    "# W2 = np.random.randn(cells_num, l1_size)\n",
    "\n",
    "\n",
    "# \"He Initialization\" technique\n",
    "W1 = np.random.randn(l1_size, cells_num) * np.sqrt(2/cells_num)\n",
    "B1 = np.zeros(l1_size,)\n",
    "W2 = np.random.randn(cells_num, l1_size) * np.sqrt(2/l1_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexes for cells [22.  8. 12.  7. 14.  0.  4.  9. 19. 21. 13.  1. 26.  2.  6. 31. 29. 20.\n",
      " 18.  3.  5. 25. 30. 27. 10. 17. 11. 16. 24. 15. 23. 28.]\n",
      "\n",
      " 4.019971616023234\n",
      "\n",
      " quad_cells \n",
      " [[ 5. 11. 13. 19.  6. 20. 14.  3.]\n",
      " [ 1.  7. 24. 26.  2. 10.  4. 29.]\n",
      " [27. 25. 18.  8. 17.  9.  0. 30.]\n",
      " [28. 21. 12. 23. 31. 16. 22. 15.]]\n"
     ]
    }
   ],
   "source": [
    "# First feed forward\n",
    "\n",
    "l1_outs = relu(np.dot(W1, cell_reps)+B1)\n",
    "l2_outs = np.dot(W2, l1_outs)\n",
    "l2_outs = np.round(l2_outs, 16)\n",
    "\n",
    "# Indexes based on the final layer outputs.\n",
    "sorted_outs = np.sort(l2_outs)\n",
    "indexes = []\n",
    "for i in range(0, cells_num):\n",
    "    index = np.where(sorted_outs == l2_outs[i])\n",
    "    indexes = np.append(indexes, index)\n",
    "    \n",
    "yijkls = [] # Yijkls based on the assigned indexes\n",
    "dijkls = []\n",
    "for i in range(0, int(cells_num/4)):\n",
    "    j = i + cells_num/4\n",
    "    k = i + 2 * cells_num/4\n",
    "    l = i + 3 * cells_num/4\n",
    "\n",
    "    celli = np.where(indexes == i)\n",
    "    cellj = np.where(indexes == j)\n",
    "    cellk = np.where(indexes == k)\n",
    "    celll = np.where(indexes == l)\n",
    "\n",
    "    yijkl = (xprbs[celli] + xprbs[cellj] + xprbs[cellk] + xprbs[celll])\\\n",
    "           /(prbs[celli] + prbs[cellj] + prbs[cellk] + prbs[celll])\n",
    "    yijkls = np.append(yijkls, yijkl)\n",
    "\n",
    "    dijkl = x2prbs[celli] + yijkl**2 * prbs[celli] - yijkl *2 * xprbs[celli]\\\n",
    "          + x2prbs[cellj] + yijkl**2 * prbs[cellj] - yijkl *2 * xprbs[cellj]\\\n",
    "          + x2prbs[cellk] + yijkl**2 * prbs[cellk] - yijkl *2 * xprbs[cellk]\\\n",
    "          + x2prbs[celll] + yijkl**2 * prbs[celll] - yijkl *2 * xprbs[celll]\n",
    "    dijkls = np.append(dijkls, dijkl)\n",
    "\n",
    "distortion = np.round(sum(dijkls), 16) # The Eve's distortion based on the assigned indexes\n",
    "\n",
    "print('indexes for cells', indexes)\n",
    "print('\\n', distortion)\n",
    "\n",
    "quads = []\n",
    "for i in range(int(cells_num/4)):\n",
    "    quad_cell1 = np.where(indexes==i)\n",
    "    quad_cell2 = np.where(indexes==i+cells_num/4)\n",
    "    quad_cell3 = np.where(indexes==i+2*cells_num/4)\n",
    "    quad_cell4 = np.where(indexes==i+3*cells_num/4)\n",
    "    quad = [quad_cell1, quad_cell2, quad_cell3, quad_cell4]\n",
    "    quads = np.append(quads, quad)\n",
    "\n",
    "quads = np.transpose(np.reshape(quads,[int(cells_num/4), 4]))\n",
    "print('\\n','quad_cells','\\n', quads)\n",
    "\n",
    "tW1 = W1.copy()\n",
    "tB1 = B1.copy()\n",
    "tW2 = W2.copy()\n",
    "\n",
    "\n",
    "past_velocity1 = 0 # Past velocity for momentum\n",
    "past_velocity_b1 = 0\n",
    "past_velocity2 = 0\n",
    "\n",
    "\n",
    "m_adam1 = 0 # For Adam\n",
    "v_adam1 = 0\n",
    "m_adam_b1 = 0\n",
    "v_adam_b1 = 0\n",
    "m_adam2 = 0\n",
    "v_adam2 = 0\n",
    "\n",
    "\n",
    "Gt1 = 0 # For Adagrad\n",
    "Gtb1 = 0\n",
    "Gt2 = 0\n",
    "adagrad_eps = 0.0001\n",
    "\n",
    "\n",
    "past1 = 0.001 # For conjugate gradient\n",
    "pastp1 = 0.001\n",
    "pastb1 = 0.001\n",
    "pastpb1 = 0.001\n",
    "    \n",
    "past2 = 0.001\n",
    "pastp2 = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the network\n",
    "'''This part provides the derivative of the distortion w.r.t. the weights\n",
    "for the back propagation. The prefix 'b' shows that the variables are\n",
    "calculated temporarily for the gradient descent'''\n",
    "\n",
    "learning_rate = 0.1\n",
    "epsilon = 0.1\n",
    " \n",
    "momentum = 0.55\n",
    "\n",
    "beta_1 = 0.9 # Parameters of Adam\n",
    "beta_2 = 0.999\n",
    "\n",
    "\n",
    "iterations = 1000\n",
    "\n",
    "for ii in range (1, iterations):\n",
    "    l1_gradients = [] # Gradients of layer 1 weights\n",
    "#     learning_rate = 100/ii\n",
    "    for i in range (0, l1_size):\n",
    "        for j in range (0, cells_num):\n",
    "            bW1 = tW1.copy()\n",
    "            bW1[i][j] = tW1 [i][j] + epsilon\n",
    "            b_l1_outs = relu(np.dot(bW1, cell_reps)+tB1)\n",
    "            b_l2_outs = np.dot(tW2, b_l1_outs)\n",
    "            b_l2_outs = np.round(b_l2_outs, 16)\n",
    "            \n",
    "            for p in range(0, cells_num-1):\n",
    "                for q in range (p+1, cells_num):\n",
    "                    if b_l2_outs[p] == b_l2_outs[q]:\n",
    "                        b_l2_outs[q] += np.random.rand(1,1)-0.5\n",
    "            \n",
    "            b_sorted_outs = np.sort(b_l2_outs)\n",
    "            b_indexes = []\n",
    "            for k in range(0, cells_num):\n",
    "                b_index = np.where(b_sorted_outs == b_l2_outs[k])\n",
    "                b_indexes = np.append(b_indexes, b_index)\n",
    "\n",
    "            byijkls = [] # Yijkls based on the assigned indexes\n",
    "            bdijkls = []\n",
    "            for i in range(0, int(cells_num/4)):\n",
    "                j = i + cells_num/4\n",
    "                k = i + 2 * cells_num/4\n",
    "                l = i + 3 * cells_num/4\n",
    "\n",
    "                bcelli = np.where(b_indexes == i)\n",
    "                bcellj = np.where(b_indexes == j)\n",
    "                bcellk = np.where(b_indexes == k)\n",
    "                bcelll = np.where(b_indexes == l)\n",
    "\n",
    "                byijkl = (xprbs[bcelli] + xprbs[bcellj] + xprbs[bcellk] + xprbs[bcelll])\\\n",
    "                        /(prbs[bcelli] + prbs[bcellj] + prbs[bcellk] + prbs[bcelll])\n",
    "                byijkls = np.append(byijkls, byijkl)\n",
    "\n",
    "                bdijkl = x2prbs[bcelli] + byijkl**2 * prbs[bcelli] - byijkl *2 * xprbs[bcelli]\\\n",
    "                       + x2prbs[bcellj] + byijkl**2 * prbs[bcellj] - byijkl *2 * xprbs[bcellj]\\\n",
    "                       + x2prbs[bcellk] + byijkl**2 * prbs[bcellk] - byijkl *2 * xprbs[bcellk]\\\n",
    "                       + x2prbs[bcelll] + byijkl**2 * prbs[bcelll] - byijkl *2 * xprbs[bcelll]\n",
    "                bdijkls = np.append(bdijkls, bdijkl)\n",
    "\n",
    "            b_distortion = np.round(sum(bdijkls), 16)\n",
    "                        \n",
    "            l1_gradient = (b_distortion - distortion)/epsilon\n",
    "            l1_gradients = np.append(l1_gradients, l1_gradient)\n",
    "            \n",
    "    l1_gradients = np.reshape(l1_gradients, [l1_size, cells_num])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    l1_biases_gradients = [] # Gradients of the layer 1 biases\n",
    "    for i in range (0, l1_size):\n",
    "        bB1 = tB1.copy()\n",
    "        bB1 [i] = tB1 [i] + epsilon\n",
    "        b_l1_outs = relu(np.dot(tW1, cell_reps)+bB1)\n",
    "        b_l2_outs = np.dot(tW2, b_l1_outs)\n",
    "        b_l2_outs = np.round(b_l2_outs, 16)\n",
    "        \n",
    "        for p in range(0, cells_num-1):\n",
    "            for q in range (p+1, cells_num):\n",
    "                if b_l2_outs[p] == b_l2_outs[q]:\n",
    "                    b_l2_outs[q] += np.random.rand(1,1)-0.5\n",
    "\n",
    "        b_sorted_outs = np.sort(b_l2_outs)\n",
    "        b_indexes = []\n",
    "        \n",
    "        for k in range(0, cells_num):\n",
    "            b_index = np.where(b_sorted_outs == b_l2_outs[k])\n",
    "            b_indexes = np.append(b_indexes, b_index)\n",
    "\n",
    "            byijkls = [] # Yijkls based on the assigned indexes\n",
    "            bdijkls = []\n",
    "            for i in range(0, int(cells_num/4)):\n",
    "                j = i + cells_num/4\n",
    "                k = i + 2 * cells_num/4\n",
    "                l = i + 3 * cells_num/4\n",
    "\n",
    "                bcelli = np.where(b_indexes == i)\n",
    "                bcellj = np.where(b_indexes == j)\n",
    "                bcellk = np.where(b_indexes == k)\n",
    "                bcelll = np.where(b_indexes == l)\n",
    "\n",
    "                byijkl = (xprbs[bcelli] + xprbs[bcellj] + xprbs[bcellk] + xprbs[bcelll])\\\n",
    "                        /(prbs[bcelli] + prbs[bcellj] + prbs[bcellk] + prbs[bcelll])\n",
    "                byijkls = np.append(byijkls, byijkl)\n",
    "\n",
    "                bdijkl = x2prbs[bcelli] + byijkl**2 * prbs[bcelli] - byijkl *2 * xprbs[bcelli]\\\n",
    "                       + x2prbs[bcellj] + byijkl**2 * prbs[bcellj] - byijkl *2 * xprbs[bcellj]\\\n",
    "                       + x2prbs[bcellk] + byijkl**2 * prbs[bcellk] - byijkl *2 * xprbs[bcellk]\\\n",
    "                       + x2prbs[bcelll] + byijkl**2 * prbs[bcelll] - byijkl *2 * xprbs[bcelll]\n",
    "                bdijkls = np.append(bdijkls, bdijkl)\n",
    "\n",
    "            b_distortion = np.round(sum(bdijkls), 16)\n",
    "            \n",
    "        l1_biases_gradient = (b_distortion - distortion)/epsilon\n",
    "        l1_biases_gradients = np.append(l1_biases_gradients, l1_biases_gradient)\n",
    "    \n",
    "           \n",
    "        \n",
    "        \n",
    "    l2_gradients = [] # Gradients of layer 2 weights\n",
    "    for i in range (0, cells_num):\n",
    "        for j in range (0, l1_size):\n",
    "            bW2 = tW2.copy()\n",
    "            bW2[i][j] = tW2[i][j] + epsilon\n",
    "            b_l1_outs = relu(np.dot(tW1, cell_reps)+tB1)\n",
    "            b_l2_outs = np.dot(bW2, b_l1_outs)\n",
    "            b_l2_outs = np.round(b_l2_outs, 16)\n",
    "            \n",
    "            for p in range(0, cells_num-1):\n",
    "                for q in range (p+1, cells_num):\n",
    "                    if b_l2_outs[p] == b_l2_outs[q]:\n",
    "                        b_l2_outs[q] += np.random.rand(1,1)-0.5\n",
    "\n",
    "\n",
    "            b_sorted_outs = np.sort(b_l2_outs)\n",
    "            b_indexes = []\n",
    "            for k in range(0, cells_num):\n",
    "                b_index = np.where(b_sorted_outs == b_l2_outs[k])\n",
    "                b_indexes = np.append(b_indexes, b_index)\n",
    "\n",
    "            byijkls = [] # Yijkls based on the assigned indexes\n",
    "            bdijkls = []\n",
    "            for i in range(0, int(cells_num/4)):\n",
    "                j = i + cells_num/4\n",
    "                k = i + 2 * cells_num/4\n",
    "                l = i + 3 * cells_num/4\n",
    "\n",
    "                bcelli = np.where(b_indexes == i)\n",
    "                bcellj = np.where(b_indexes == j)\n",
    "                bcellk = np.where(b_indexes == k)\n",
    "                bcelll = np.where(b_indexes == l)\n",
    "\n",
    "                byijkl = (xprbs[bcelli] + xprbs[bcellj] + xprbs[bcellk] + xprbs[bcelll])\\\n",
    "                        /(prbs[bcelli] + prbs[bcellj] + prbs[bcellk] + prbs[bcelll])\n",
    "                byijkls = np.append(byijkls, byijkl)\n",
    "\n",
    "                bdijkl = x2prbs[bcelli] + byijkl**2 * prbs[bcelli] - byijkl *2 * xprbs[bcelli]\\\n",
    "                       + x2prbs[bcellj] + byijkl**2 * prbs[bcellj] - byijkl *2 * xprbs[bcellj]\\\n",
    "                       + x2prbs[bcellk] + byijkl**2 * prbs[bcellk] - byijkl *2 * xprbs[bcellk]\\\n",
    "                       + x2prbs[bcelll] + byijkl**2 * prbs[bcelll] - byijkl *2 * xprbs[bcelll]\n",
    "                bdijkls = np.append(bdijkls, bdijkl)\n",
    "\n",
    "            b_distortion = np.round(sum(bdijkls), 16)\n",
    "                        \n",
    "            l2_gradient = (b_distortion - distortion)/epsilon\n",
    "            l2_gradients = np.append(l2_gradients, l2_gradient)\n",
    "            \n",
    "    l2_gradients = np.reshape(l2_gradients, [cells_num, l1_size])\n",
    "    \n",
    "\n",
    "# # Now, we update the weights.   \n",
    "#     tW1 = tW1 + learning_rate * l1_gradients\n",
    "#     tB1 = tB1 + learning_rate * l1_biases_gradients\n",
    "#     tW2 = tW2 + learning_rate * l2_gradients\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # We update the weights with momentum.\n",
    "    velocity1 = past_velocity1 * momentum + learning_rate *  l1_gradients\n",
    "    tW1 = tW1 - momentum * velocity1 + learning_rate * l1_gradients\n",
    "    past_velocity1 = velocity1 \n",
    "    \n",
    "    velocity_b1 = past_velocity_b1 * momentum + learning_rate *  l1_biases_gradients\n",
    "    tB1 = tB1 - momentum * velocity_b1 + learning_rate * l1_biases_gradients\n",
    "    past_velocity_b1 = velocity_b1\n",
    "    \n",
    "    velocity2 = past_velocity2 * momentum + learning_rate *  l2_gradients\n",
    "    tW2 = tW2 - momentum * velocity2 + learning_rate * l2_gradients\n",
    "    past_velocity2 = velocity2\n",
    "    \n",
    "    \n",
    "#     # momentum way 2\n",
    "#     velocity1 = learning_rate * l1_gradients + momentum * past_velocity1\n",
    "#     tW1 = tW1 + velocity1\n",
    "#     past_velocity1 = velocity1\n",
    "    \n",
    "#     velocity2 = learning_rate * l2_gradients + momentum * past_velocity2\n",
    "#     tW2 = tW2 + velocity2\n",
    "#     past_velocity2 = velocity2\n",
    "    \n",
    "#     velocity_b1 = learning_rate * l1_biases_gradients + momentum * past_velocity_b1\n",
    "#     tB1 = tB1 + velocity_b1\n",
    "#     past_velocity_b1 = velocity_b1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Here, we implement the Adam algorithm.\n",
    "\n",
    "#     m_adam1 = beta_1 * m_adam1 + (1 - beta_1) * l1_gradients\n",
    "#     v_adam1 = beta_2 * v_adam1 + (1 - beta_2) * np.power(l1_gradients, 2)\n",
    "#     m_hat1 = m_adam1 / (1 - np.power(beta_1, ii))\n",
    "#     v_hat1 = v_adam1 / (1 - np.power(beta_2, ii))\n",
    "#     tW1 = tW1 + learning_rate * m_hat1 / (np.sqrt(v_hat1) + 0.001)\n",
    "    \n",
    "#     m_adam_b1 = beta_1 * m_adam_b1 + (1 - beta_1) * l1_biases_gradients\n",
    "#     v_adam_b1 = beta_2 * v_adam_b1 + (1 - beta_2) * np.power(l1_biases_gradients, 2)\n",
    "#     m_hat_b1 = m_adam_b1 / (1 - np.power(beta_1, ii))\n",
    "#     v_hat_b1 = v_adam_b1 / (1 - np.power(beta_2, ii))\n",
    "#     tB1 = tB1 + learning_rate * m_hat_b1 / (np.sqrt(v_hat_b1) + 0.001)\n",
    "    \n",
    "#     m_adam2 = beta_1 * m_adam2 + (1 - beta_1) * l2_gradients\n",
    "#     v_adam2 = beta_2 * v_adam2 + (1 - beta_2) * np.power(l2_gradients, 2)\n",
    "#     m_hat2 = m_adam2 / (1 - np.power(beta_1, ii))\n",
    "#     v_hat2 = v_adam2 / (1 - np.power(beta_2, ii))\n",
    "#     tW2 = tW2 + learning_rate * m_hat2 / (np.sqrt(v_hat2) + 0.001)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# # Adagrad\n",
    "#     Gt1 += np.dot(l1_gradients, np.transpose(l1_gradients))\n",
    "#     Gt1_diag_elements = np.diag(Gt1)\n",
    "#     Gt1_diag = np.zeros(np.shape(Gt1))\n",
    "#     np.fill_diagonal(Gt1_diag,Gt1_diag_elements)\n",
    "#     lr1_denominator = np.sqrt(adagrad_eps + Gt1_diag)\n",
    "    \n",
    "# #     Gtb1 += np.dot(l1_biases_gradients, np.transpose(l1_biases_gradients))\n",
    "# #     Gtb1_diag_elements = np.diag(Gtb1)\n",
    "# #     Gtb1_diag = np.zeros(np.shape(Gtb1))\n",
    "# #     np.fill_diagonal(Gtb1_diag,Gtb1_diag_elements)\n",
    "# #     lrb1_denominator = np.sqrt(adagrad_eps + Gtb1_diag)\n",
    "    \n",
    "#     Gt2 += np.dot(l2_gradients, np.transpose(l2_gradients))\n",
    "#     Gt2_diag_elements = np.diag(Gt2)\n",
    "#     Gt2_diag = np.zeros(np.shape(Gt2))\n",
    "#     np.fill_diagonal(Gt2_diag,Gt2_diag_elements)\n",
    "#     lr2_denominator = np.sqrt(adagrad_eps + Gt2_diag)\n",
    "    \n",
    "        \n",
    "#     tW1 = tW1 + learning_rate/lr1_denominator * l1_gradients\n",
    "#     tB1 = tB1 + learning_rate * l1_biases_gradients\n",
    "#     tW2 = tW2 + learning_rate/lr2_denominator * l2_gradients\n",
    "    \n",
    "    \n",
    "       \n",
    "    \n",
    "# # Conjugate gradient\n",
    "#     beta1 = np.dot(np.transpose(l1_gradients - past1),l1_gradients)/\\\n",
    "#             (np.dot(np.transpose(past1),past1)+0.001)\n",
    "#     p1 = -l1_gradients + beta1 * pastp1\n",
    "#     past1 = l1_gradients\n",
    "#     pastp1 = p1\n",
    "    \n",
    "#     betab1 = np.dot(np.transpose(l1_biases_gradients - pastb1),l1_biases_gradients)/\\\n",
    "#              (np.dot(np.transpose(pastb1),pastb1)+0.001)\n",
    "#     pb1 = -l1_biases_gradients + betab1 * pastpb1\n",
    "#     pastb1 = l1_biases_gradients\n",
    "#     pastpb1 = pb1\n",
    "    \n",
    "#     beta2 = np.dot(np.transpose(l2_gradients - past2),l2_gradients)/\\\n",
    "#             (np.dot(np.transpose(past2),past2)+0.001)\n",
    "#     p2 = -l2_gradients + beta2 * pastp2\n",
    "#     past2 = l2_gradients\n",
    "#     pastp2 = p2\n",
    "    \n",
    "          \n",
    "#     tW1 = tW1 + learning_rate * (l1_gradients + beta1 * pastp1)\n",
    "#     tB1 = tB1 + learning_rate * (l1_biases_gradients + betab1 * pastpb1)\n",
    "#     tW2 = tW2 + learning_rate * (l2_gradients + beta2 * pastp2)    \n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    l1_outs = relu(np.dot(tW1,cell_reps)+tB1)\n",
    "    l2_outs = np.dot(tW2, l1_outs)\n",
    "    l2_outs = np.round(l2_outs, 16)\n",
    "    \n",
    "    for p in range(0, cells_num-1):\n",
    "        for q in range (p+1, cells_num):\n",
    "            if l2_outs[p] == l2_outs[q]:\n",
    "                l2_outs[q] += np.random.rand(1,1)-0.5\n",
    "   \n",
    "\n",
    "    # We assigned the indexes based on the final layer outputs.\n",
    "    sorted_outs = np.sort(l2_outs)\n",
    "    indexes = []\n",
    "    for i in range(0, cells_num):\n",
    "        index = np.where(sorted_outs == l2_outs[i])\n",
    "        indexes = np.append(indexes, index)\n",
    "\n",
    "    #print(indexes)\n",
    "    \n",
    "    yijkls = [] # Yijkls based on the assigned indexes\n",
    "    dijkls = []\n",
    "    for i in range(0, int(cells_num/4)):\n",
    "        j = i + cells_num/4\n",
    "        k = i + 2 * cells_num/4\n",
    "        l = i + 3 * cells_num/4\n",
    "\n",
    "        celli = np.where(indexes == i)\n",
    "        cellj = np.where(indexes == j)\n",
    "        cellk = np.where(indexes == k)\n",
    "        celll = np.where(indexes == l)\n",
    "\n",
    "        yijkl = (xprbs[celli] + xprbs[cellj] + xprbs[cellk] + xprbs[celll])\\\n",
    "               /(prbs[celli] + prbs[cellj] + prbs[cellk] + prbs[celll])\n",
    "        yijkls = np.append(yijkls, yijkl)\n",
    "\n",
    "        dijkl = x2prbs[celli] + yijkl**2 * prbs[celli] - yijkl *2 * xprbs[celli]\\\n",
    "              + x2prbs[cellj] + yijkl**2 * prbs[cellj] - yijkl *2 * xprbs[cellj]\\\n",
    "              + x2prbs[cellk] + yijkl**2 * prbs[cellk] - yijkl *2 * xprbs[cellk]\\\n",
    "              + x2prbs[celll] + yijkl**2 * prbs[celll] - yijkl *2 * xprbs[celll]\n",
    "        dijkls = np.append(dijkls, dijkl)\n",
    "\n",
    "    distortion = np.round(sum(dijkls), 16) # The Eve's distortion based on the assigned indexes\n",
    "\n",
    "    \n",
    "    print(distortion)\n",
    "\n",
    "print(indexes)\n",
    "quads = []\n",
    "for i in range(int(cells_num/4)):\n",
    "    quad_cell1 = np.where(indexes==i)\n",
    "    quad_cell2 = np.where(indexes==i+cells_num/4)\n",
    "    quad_cell3 = np.where(indexes==i+2*cells_num/4)\n",
    "    quad_cell4 = np.where(indexes==i+3*cells_num/4)\n",
    "    quad = [quad_cell1, quad_cell2, quad_cell3, quad_cell4]\n",
    "    quads = np.append(quads, quad)\n",
    "\n",
    "quads = np.transpose(np.reshape(quads,[int(cells_num/4), 4]))\n",
    "print('\\n', quads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.987011290272516"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
